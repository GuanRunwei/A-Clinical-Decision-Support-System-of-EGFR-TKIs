{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file = 'newnew.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe = pd.read_excel(new_file, sheet_name=0)\n",
    "new_dataframe1 = pd.read_excel(new_file, sheet_name=2).iloc[:, range(16)]\n",
    "new_dataframe2 = pd.read_excel(new_file, sheet_name=2).iloc[:, range(17,31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158 entries, 0 to 157\n",
      "Data columns (total 12 columns):\n",
      "性别             158 non-null int64\n",
      "年龄             158 non-null int64\n",
      "吸烟             158 non-null int64\n",
      "部位             158 non-null int64\n",
      "原发灶大小          158 non-null int64\n",
      "骨转移            158 non-null int64\n",
      "脑转移            158 non-null int64\n",
      "肝转             158 non-null int64\n",
      "肺内转移           158 non-null int64\n",
      "胸膜转移           158 non-null int64\n",
      "治疗方案           158 non-null int64\n",
      "疗效差0差1好/9个月    158 non-null int64\n",
      "dtypes: int64(12)\n",
      "memory usage: 14.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Dataset1\n",
    "new_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158 entries, 0 to 157\n",
      "Data columns (total 16 columns):\n",
      "性别             158 non-null int64\n",
      "年龄             158 non-null int64\n",
      "吸烟             158 non-null int64\n",
      "部位             158 non-null int64\n",
      "原发灶大小          158 non-null int64\n",
      "骨转移            158 non-null int64\n",
      "脑转移            158 non-null int64\n",
      "肝转             158 non-null int64\n",
      "肺内转移           158 non-null int64\n",
      "胸膜转移           158 non-null int64\n",
      "治疗方案           158 non-null int64\n",
      "突变情况123        158 non-null int64\n",
      "TP53           158 non-null int64\n",
      "rb1            158 non-null int64\n",
      "pik3ca         158 non-null int64\n",
      "疗效差1差2好/9个月    158 non-null int64\n",
      "dtypes: int64(16)\n",
      "memory usage: 19.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Dataset2\n",
    "new_dataframe1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158 entries, 0 to 157\n",
      "Data columns (total 14 columns):\n",
      "性别.1             158 non-null int64\n",
      "年龄.1             158 non-null int64\n",
      "吸烟.1             158 non-null int64\n",
      "部位.1             158 non-null int64\n",
      "原发灶大小.1          158 non-null int64\n",
      "骨转移.1            158 non-null int64\n",
      "脑转移.1            158 non-null int64\n",
      "肝转.1             158 non-null int64\n",
      "肺内转移.1           158 non-null int64\n",
      "胸膜转移.1           158 non-null int64\n",
      "治疗方案.1           158 non-null int64\n",
      "突变情况123.1        158 non-null int64\n",
      "N                158 non-null int64\n",
      "疗效差1差2好/9个月.1    158 non-null int64\n",
      "dtypes: int64(14)\n",
      "memory usage: 17.4 KB\n"
     ]
    }
   ],
   "source": [
    "# Dataset3\n",
    "new_dataframe2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset for outside validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>性别</th>\n",
       "      <th>年龄</th>\n",
       "      <th>吸烟</th>\n",
       "      <th>部位</th>\n",
       "      <th>原发灶大小</th>\n",
       "      <th>骨转移</th>\n",
       "      <th>脑转移</th>\n",
       "      <th>肝转</th>\n",
       "      <th>肺内转移</th>\n",
       "      <th>胸膜转移</th>\n",
       "      <th>治疗方案</th>\n",
       "      <th>疗效差0差1好/9个月</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    性别  年龄  吸烟  部位  原发灶大小  骨转移  脑转移  肝转  肺内转移  胸膜转移  治疗方案  疗效差0差1好/9个月\n",
       "0    1  56   0   1      1    1    1   1     1     0     1            0\n",
       "1    2  81   0   2      2    1    1   0     1     1     1            0\n",
       "2    2  75   0   1      2    1    0   0     1     1     1            0\n",
       "3    2  74   0   2      1    1    0   1     1     0     1            1\n",
       "4    1  59   0   1      2    1    0   0     0     1     1            1\n",
       "5    2  71   0   2      2    1    0   0     1     1     1            1\n",
       "6    2  51   0   2      3    0    0   0     1     0     1            0\n",
       "7    1  62   0   1      2    0    0   0     1     1     1            1\n",
       "8    2  67   0   1      2    1    0   0     1     1     1            1\n",
       "9    1  77   0   2      2    0    0   0     1     1     1            1\n",
       "10   2  85   0   2      2    1    0   0     1     1     1            1\n",
       "11   2  62   0   2      2    0    1   0     1     1     1            0\n",
       "12   1  89   0   1      3    0    0   0     1     1     1            1\n",
       "13   1  72   1   2      2    1    0   0     1     0     1            1\n",
       "14   2  47   0   2      2    1    1   0     1     1     1            0\n",
       "15   1  68   1   2      2    0    0   0     1     1     1            1\n",
       "16   1  76   1   1      2    1    0   0     1     0     1            1\n",
       "17   1  70   0   1      2    0    0   0     1     1     1            0\n",
       "18   1  46   0   2      1    1    0   0     1     0     1            1\n",
       "19   2  47   0   2      1    0    0   0     1     0     1            1\n",
       "20   2  57   0   2      2    1    1   0     0     0     1            1\n",
       "21   2  64   0   1      2    0    0   0     1     1     1            1\n",
       "22   2  62   0   1      2    0    0   0     0     1     1            1\n",
       "23   1  58   0   1      3    1    0   0     1     1     1            1\n",
       "24   1  62   0   2      1    0    1   0     1     1     1            0\n",
       "25   2  81   0   1      1    0    0   0     1     0     1            1\n",
       "26   1  64   0   2      2    1    1   0     1     1     1            0\n",
       "27   2  49   0   1      2    1    0   0     1     0     1            1\n",
       "28   2  68   0   1      2    1    0   0     0     0     1            1\n",
       "29   1  78   0   2      2    1    0   1     1     0     1            1"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## outside validation\n",
    "test_frame1 = pd.read_excel(new_file, sheet_name=1)\n",
    "test_frame2 = pd.read_excel(new_file, sheet_name=3).iloc[:, range(16)]\n",
    "test_frame3 = pd.read_excel(new_file, sheet_name=3).iloc[:, range(17,31)]\n",
    "test_frame1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset1\n",
    "X_first = new_dataframe.iloc[:,range(0,11)]\n",
    "y_first = new_dataframe.iloc[:, -1]  # 第二个指标\n",
    "X_first = np.asarray(X_first)\n",
    "\n",
    "# Dataset2\n",
    "X_second = new_dataframe1.iloc[:,range(0,15)]\n",
    "y_second = new_dataframe1.iloc[:, -1]  # 第二个指标\n",
    "X_second = np.asarray(X_second)\n",
    "\n",
    "# Dataset3\n",
    "X_third = new_dataframe2.iloc[:,range(0,13)]\n",
    "y_third = new_dataframe2.iloc[:, -1]  # 第二个指标\n",
    "X_third = np.asarray(X_third)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 65,  2, ...,  0,  0,  1],\n",
       "       [ 1, 68,  1, ...,  1,  0,  1],\n",
       "       [ 2, 63,  2, ...,  1,  0,  1],\n",
       "       ...,\n",
       "       [ 2, 58,  2, ...,  0,  0,  2],\n",
       "       [ 2, 66,  2, ...,  1,  0,  2],\n",
       "       [ 2, 52,  2, ...,  0,  0,  2]], dtype=int64)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_first = np.array(y_first)\n",
    "y_second = np.array(y_second)\n",
    "y_third = np.array(y_third)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., 62.,  1.,  ...,  0.,  0.,  2.],\n",
       "        [ 1., 58.,  2.,  ...,  0.,  0.,  1.],\n",
       "        [ 2., 78.,  2.,  ...,  0.,  0.,  1.],\n",
       "        ...,\n",
       "        [ 2., 43.,  2.,  ...,  1.,  0.,  2.],\n",
       "        [ 2., 68.,  2.,  ...,  1.,  0.,  1.],\n",
       "        [ 2., 55.,  2.,  ...,  0.,  0.,  2.]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_first, X_test_first, y_train_first, y_test_first= train_test_split(X_first, y_first, test_size=0.3, random_state=100)\n",
    "X_test_first = torch.Tensor(X_test_first)\n",
    "X_train_first = torch.Tensor(X_train_first)\n",
    "y_train_first = torch.Tensor(y_train_first)\n",
    "y_test_first = torch.Tensor(y_test_first)\n",
    "X_train_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_second, X_test_second, y_train_second, y_test_second = train_test_split(X_second, y_second, test_size=0.3, random_state=100)\n",
    "X_train_second = torch.Tensor(X_train_second)\n",
    "X_test_second = torch.Tensor(X_test_second)\n",
    "y_train_second = torch.Tensor(y_train_second)\n",
    "y_test_second = torch.Tensor(y_test_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "        0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 1.])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_third, X_test_third, y_train_third, y_test_third = train_test_split(X_third, y_third, test_size=0.3, random_state=100)\n",
    "X_train_third, X_test_third, y_train_third, y_test_third = torch.Tensor(X_train_third), torch.Tensor(X_test_third),torch.Tensor(y_train_third),torch.Tensor(y_test_third)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for Dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward_first(torch.nn.Module):\n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Feedforward_first, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.batchnorm = torch.nn.BatchNorm1d(self.hidden_size)\n",
    "            self.laynorm = torch.nn.LayerNorm(self.input_size)\n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size, bias=True)\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, 5, bias=True)\n",
    "            self.fc3 = torch.nn.Linear(5, 1, bias=True)\n",
    "            self.sigmoid = torch.nn.Sigmoid()\n",
    "        def forward(self, x):\n",
    "            hidden = self.fc1(x)\n",
    "            batchnorm = self.batchnorm(hidden)\n",
    "            layborm = self.batchnorm(batchnorm)\n",
    "            relu = self.relu(batchnorm)\n",
    "            output = self.fc2(relu)\n",
    "            output = self.fc3(output)\n",
    "            output = self.sigmoid(output)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_first.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Feedforward_first(X_train_first.shape[1],10)\n",
    "criterion1 = torch.nn.BCELoss()\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr = 0.01, weight_decay= 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 0.6244868040084839\n",
      "Epoch 1: train loss: 0.6133076548576355\n",
      "Epoch 2: train loss: 0.6051017045974731\n",
      "Epoch 3: train loss: 0.5989736318588257\n",
      "Epoch 4: train loss: 0.5943288207054138\n",
      "Epoch 5: train loss: 0.5894075632095337\n",
      "Epoch 6: train loss: 0.5836519002914429\n",
      "Epoch 7: train loss: 0.5773817300796509\n",
      "Epoch 8: train loss: 0.5706023573875427\n",
      "Epoch 9: train loss: 0.5638580322265625\n",
      "Epoch 10: train loss: 0.5584702491760254\n",
      "Epoch 11: train loss: 0.5518344640731812\n",
      "Epoch 12: train loss: 0.5441088080406189\n",
      "Epoch 13: train loss: 0.5366925001144409\n",
      "Epoch 14: train loss: 0.5275519490242004\n",
      "Epoch 15: train loss: 0.5171442031860352\n",
      "Epoch 16: train loss: 0.5066359639167786\n",
      "Epoch 17: train loss: 0.49640965461730957\n",
      "Epoch 18: train loss: 0.48884525895118713\n",
      "Epoch 19: train loss: 0.4825907051563263\n",
      "Epoch 20: train loss: 0.4774806499481201\n",
      "Epoch 21: train loss: 0.47192177176475525\n",
      "Epoch 22: train loss: 0.4659217894077301\n",
      "Epoch 23: train loss: 0.4597175121307373\n",
      "Epoch 24: train loss: 0.4531801640987396\n",
      "Epoch 25: train loss: 0.44740691781044006\n",
      "Epoch 26: train loss: 0.44258102774620056\n",
      "Epoch 27: train loss: 0.43689414858818054\n",
      "Epoch 28: train loss: 0.4300641417503357\n",
      "Epoch 29: train loss: 0.42420661449432373\n",
      "Epoch 30: train loss: 0.41808801889419556\n",
      "Epoch 31: train loss: 0.4116098880767822\n",
      "Epoch 32: train loss: 0.4052026569843292\n",
      "Epoch 33: train loss: 0.3985016644001007\n",
      "Epoch 34: train loss: 0.3903847634792328\n",
      "Epoch 35: train loss: 0.3828815817832947\n",
      "Epoch 36: train loss: 0.3766992688179016\n",
      "Epoch 37: train loss: 0.3716174066066742\n",
      "Epoch 38: train loss: 0.3650311231613159\n",
      "Epoch 39: train loss: 0.35754844546318054\n",
      "Epoch 40: train loss: 0.3512578010559082\n",
      "Epoch 41: train loss: 0.34634271264076233\n",
      "Epoch 42: train loss: 0.34112349152565\n",
      "Epoch 43: train loss: 0.33322587609291077\n",
      "Epoch 44: train loss: 0.32547295093536377\n",
      "Epoch 45: train loss: 0.32002878189086914\n",
      "Epoch 46: train loss: 0.31257864832878113\n",
      "Epoch 47: train loss: 0.3060753643512726\n",
      "Epoch 48: train loss: 0.29791897535324097\n",
      "Epoch 49: train loss: 0.29009124636650085\n",
      "Epoch 50: train loss: 0.2841261923313141\n",
      "Epoch 51: train loss: 0.2778998613357544\n",
      "Epoch 52: train loss: 0.2704511284828186\n",
      "Epoch 53: train loss: 0.26207274198532104\n",
      "Epoch 54: train loss: 0.258057177066803\n",
      "Epoch 55: train loss: 0.2511468231678009\n",
      "Epoch 56: train loss: 0.24563036859035492\n",
      "Epoch 57: train loss: 0.2382509559392929\n",
      "Epoch 58: train loss: 0.2320617437362671\n",
      "Epoch 59: train loss: 0.2268526554107666\n",
      "Epoch 60: train loss: 0.22007670998573303\n",
      "Epoch 61: train loss: 0.2134767472743988\n",
      "Epoch 62: train loss: 0.20998193323612213\n",
      "Epoch 63: train loss: 0.2038608342409134\n",
      "Epoch 64: train loss: 0.19659791886806488\n",
      "Epoch 65: train loss: 0.19177480041980743\n",
      "Epoch 66: train loss: 0.18721094727516174\n",
      "Epoch 67: train loss: 0.18104754388332367\n",
      "Epoch 68: train loss: 0.17561402916908264\n",
      "Epoch 69: train loss: 0.1699850708246231\n",
      "Epoch 70: train loss: 0.16584336757659912\n",
      "Epoch 71: train loss: 0.16133596003055573\n",
      "Epoch 72: train loss: 0.15638317167758942\n",
      "Epoch 73: train loss: 0.15163983404636383\n",
      "Epoch 74: train loss: 0.1481664478778839\n",
      "Epoch 75: train loss: 0.14367364346981049\n",
      "Epoch 76: train loss: 0.13843363523483276\n",
      "Epoch 77: train loss: 0.13513854146003723\n",
      "Epoch 78: train loss: 0.13068394362926483\n",
      "Epoch 79: train loss: 0.1271268129348755\n",
      "Epoch 80: train loss: 0.12325017899274826\n",
      "Epoch 81: train loss: 0.12009023874998093\n",
      "Epoch 82: train loss: 0.11694222688674927\n",
      "Epoch 83: train loss: 0.11312371492385864\n",
      "Epoch 84: train loss: 0.11167272925376892\n",
      "Epoch 85: train loss: 0.10670284926891327\n",
      "Epoch 86: train loss: 0.10193774849176407\n",
      "Epoch 87: train loss: 0.09785778820514679\n",
      "Epoch 88: train loss: 0.09619834274053574\n",
      "Epoch 89: train loss: 0.09167496860027313\n",
      "Epoch 90: train loss: 0.08850466459989548\n",
      "Epoch 91: train loss: 0.08601642400026321\n",
      "Epoch 92: train loss: 0.08569160848855972\n",
      "Epoch 93: train loss: 0.08727724850177765\n",
      "Epoch 94: train loss: 0.08783341944217682\n",
      "Epoch 95: train loss: 0.07772200554609299\n",
      "Epoch 96: train loss: 0.07555609941482544\n",
      "Epoch 97: train loss: 0.07670824229717255\n",
      "Epoch 98: train loss: 0.06859710812568665\n",
      "Epoch 99: train loss: 0.06626441329717636\n"
     ]
    }
   ],
   "source": [
    "model1.train()\n",
    "epoch = 100\n",
    "loss_array = []\n",
    "for epoch in range(epoch):\n",
    "    optimizer1.zero_grad()\n",
    "    # Forward pass\n",
    "    y_pred = model1(X_train_first)\n",
    "    # Compute Loss\n",
    "    loss = criterion1(y_pred.squeeze(), y_train_first)\n",
    "    loss_array.append(float(loss.item()))\n",
    "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer1.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss Value')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_array)\n",
    "plt.title(\"Training Loss of ANN\")\n",
    "plt.xlabel(\"Epoches\")\n",
    "plt.ylabel(\"Loss Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1]\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.])\n",
      "0.7083333333333334\n"
     ]
    }
   ],
   "source": [
    "model1.eval()\n",
    "y_pred = model1(X_test_first)\n",
    "y_pred_int = []\n",
    "\n",
    "for item in y_pred:\n",
    "    y_pred_int.append(round(float(item[0])))\n",
    "print(y_pred_int)\n",
    "print(y_test_first)\n",
    "print(np.sum(y_pred_int==np.array(y_test_first))/len(y_pred_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
      "tensor([1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1.])\n",
      "0.7545454545454545\n"
     ]
    }
   ],
   "source": [
    "### accuracy on training set\n",
    "y_pred = model1(X_train_first)\n",
    "y_pred_int = []\n",
    "\n",
    "for item in y_pred:\n",
    "    y_pred_int.append(round(float(item[0])))\n",
    "print(y_pred_int)\n",
    "print(y_train_first)\n",
    "print(np.sum(y_pred_int==np.array(y_train_first))/len(y_pred_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for Dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward_second(torch.nn.Module):\n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Feedforward_second, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.batchnorm = torch.nn.BatchNorm1d(self.input_size)\n",
    "            self.laynorm = torch.nn.LayerNorm(self.input_size)\n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size, bias=True)\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, 5, bias=True)\n",
    "            self.fc3 = torch.nn.Linear(5, 1, bias=True)\n",
    "            self.sigmoid = torch.nn.Sigmoid()\n",
    "        def forward(self, x):\n",
    "            hidden = self.fc1(x)\n",
    "            batchnorm = self.batchnorm(hidden)\n",
    "            laynorm = self.laynorm(batchnorm)\n",
    "            relu = self.relu(laynorm)\n",
    "            output = self.fc2(relu)\n",
    "            output = self.fc3(output)\n",
    "            output = self.sigmoid(output)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., 62.,  1.,  ...,  1.,  0.,  0.],\n",
       "        [ 1., 58.,  2.,  ...,  0.,  0.,  0.],\n",
       "        [ 2., 78.,  2.,  ...,  1.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 2., 43.,  2.,  ...,  1.,  0.,  0.],\n",
       "        [ 2., 68.,  2.,  ...,  1.,  0.,  0.],\n",
       "        [ 2., 55.,  2.,  ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Feedforward_second(X_train_second.shape[1],15)\n",
    "criterion2 = torch.nn.BCELoss()\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr = 0.01, weight_decay= 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 0.6970109939575195\n",
      "Epoch 1: train loss: 0.6656602621078491\n",
      "Epoch 2: train loss: 0.6438060998916626\n",
      "Epoch 3: train loss: 0.626984179019928\n",
      "Epoch 4: train loss: 0.6120418310165405\n",
      "Epoch 5: train loss: 0.5975006818771362\n",
      "Epoch 6: train loss: 0.5842530727386475\n",
      "Epoch 7: train loss: 0.5728676319122314\n",
      "Epoch 8: train loss: 0.5620989203453064\n",
      "Epoch 9: train loss: 0.5516068339347839\n",
      "Epoch 10: train loss: 0.5413016676902771\n",
      "Epoch 11: train loss: 0.5305013656616211\n",
      "Epoch 12: train loss: 0.5187814831733704\n",
      "Epoch 13: train loss: 0.5066744089126587\n",
      "Epoch 14: train loss: 0.4929675757884979\n",
      "Epoch 15: train loss: 0.4781721532344818\n",
      "Epoch 16: train loss: 0.4617183208465576\n",
      "Epoch 17: train loss: 0.4444705843925476\n",
      "Epoch 18: train loss: 0.42662888765335083\n",
      "Epoch 19: train loss: 0.40823912620544434\n",
      "Epoch 20: train loss: 0.38884103298187256\n",
      "Epoch 21: train loss: 0.36930304765701294\n",
      "Epoch 22: train loss: 0.3503008782863617\n",
      "Epoch 23: train loss: 0.3339758813381195\n",
      "Epoch 24: train loss: 0.3195858895778656\n",
      "Epoch 25: train loss: 0.3066369593143463\n",
      "Epoch 26: train loss: 0.29373112320899963\n",
      "Epoch 27: train loss: 0.2807646691799164\n",
      "Epoch 28: train loss: 0.2700069546699524\n",
      "Epoch 29: train loss: 0.2611539959907532\n",
      "Epoch 30: train loss: 0.25090351700782776\n",
      "Epoch 31: train loss: 0.24030262231826782\n",
      "Epoch 32: train loss: 0.23229703307151794\n",
      "Epoch 33: train loss: 0.2227410525083542\n",
      "Epoch 34: train loss: 0.21360079944133759\n",
      "Epoch 35: train loss: 0.2043982893228531\n",
      "Epoch 36: train loss: 0.19569407403469086\n",
      "Epoch 37: train loss: 0.1920909732580185\n",
      "Epoch 38: train loss: 0.18291783332824707\n",
      "Epoch 39: train loss: 0.17845501005649567\n",
      "Epoch 40: train loss: 0.17091837525367737\n",
      "Epoch 41: train loss: 0.16600941121578217\n",
      "Epoch 42: train loss: 0.15737035870552063\n",
      "Epoch 43: train loss: 0.15311308205127716\n",
      "Epoch 44: train loss: 0.14528369903564453\n",
      "Epoch 45: train loss: 0.1423603594303131\n",
      "Epoch 46: train loss: 0.13521423935890198\n",
      "Epoch 47: train loss: 0.13046316802501678\n",
      "Epoch 48: train loss: 0.1254347860813141\n",
      "Epoch 49: train loss: 0.12034124881029129\n",
      "Epoch 50: train loss: 0.11682276427745819\n",
      "Epoch 51: train loss: 0.11074650287628174\n",
      "Epoch 52: train loss: 0.10566018521785736\n",
      "Epoch 53: train loss: 0.10112173110246658\n",
      "Epoch 54: train loss: 0.09707142412662506\n",
      "Epoch 55: train loss: 0.09454748779535294\n",
      "Epoch 56: train loss: 0.09070652723312378\n",
      "Epoch 57: train loss: 0.08805936574935913\n",
      "Epoch 58: train loss: 0.0845322459936142\n",
      "Epoch 59: train loss: 0.08120760321617126\n",
      "Epoch 60: train loss: 0.07724634557962418\n",
      "Epoch 61: train loss: 0.07498805969953537\n",
      "Epoch 62: train loss: 0.07130541652441025\n",
      "Epoch 63: train loss: 0.06696730852127075\n",
      "Epoch 64: train loss: 0.06418229639530182\n",
      "Epoch 65: train loss: 0.06100952997803688\n",
      "Epoch 66: train loss: 0.05848977342247963\n",
      "Epoch 67: train loss: 0.05429469048976898\n",
      "Epoch 68: train loss: 0.051773328334093094\n",
      "Epoch 69: train loss: 0.0491793230175972\n",
      "Epoch 70: train loss: 0.046774573624134064\n",
      "Epoch 71: train loss: 0.043185729533433914\n",
      "Epoch 72: train loss: 0.040937937796115875\n",
      "Epoch 73: train loss: 0.0400506928563118\n",
      "Epoch 74: train loss: 0.03679434955120087\n",
      "Epoch 75: train loss: 0.03522865101695061\n",
      "Epoch 76: train loss: 0.03337370231747627\n",
      "Epoch 77: train loss: 0.03028232418000698\n",
      "Epoch 78: train loss: 0.029372792690992355\n",
      "Epoch 79: train loss: 0.026978248730301857\n",
      "Epoch 80: train loss: 0.025397352874279022\n",
      "Epoch 81: train loss: 0.02382674627006054\n",
      "Epoch 82: train loss: 0.02265957184135914\n",
      "Epoch 83: train loss: 0.020575016736984253\n",
      "Epoch 84: train loss: 0.019605284556746483\n",
      "Epoch 85: train loss: 0.01820305734872818\n",
      "Epoch 86: train loss: 0.016960736364126205\n",
      "Epoch 87: train loss: 0.016182079911231995\n",
      "Epoch 88: train loss: 0.014770417474210262\n",
      "Epoch 89: train loss: 0.013738674111664295\n",
      "Epoch 90: train loss: 0.0131175322458148\n",
      "Epoch 91: train loss: 0.012007885612547398\n",
      "Epoch 92: train loss: 0.011279537342488766\n",
      "Epoch 93: train loss: 0.01070859283208847\n",
      "Epoch 94: train loss: 0.01014435850083828\n",
      "Epoch 95: train loss: 0.009363159537315369\n",
      "Epoch 96: train loss: 0.008811647072434425\n",
      "Epoch 97: train loss: 0.008205282501876354\n",
      "Epoch 98: train loss: 0.007848014123737812\n",
      "Epoch 99: train loss: 0.007550244219601154\n"
     ]
    }
   ],
   "source": [
    "model2.train()\n",
    "epoch = 100\n",
    "loss_array = []\n",
    "for epoch in range(epoch):\n",
    "    optimizer2.zero_grad()\n",
    "    # Forward pass\n",
    "    y_pred = model2(X_train_second)\n",
    "    # Compute Loss\n",
    "    loss = criterion2(y_pred.squeeze(), y_train_second)\n",
    "    loss_array.append(float(loss.item()))\n",
    "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer2.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model2, \"ann_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss Value')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_array)\n",
    "plt.title(\"Training Loss of ANN\")\n",
    "plt.xlabel(\"Epoches\")\n",
    "plt.ylabel(\"Loss Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "tensor([1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1.])\n",
      "0.8909090909090909\n"
     ]
    }
   ],
   "source": [
    "model2.eval()\n",
    "y_pred = model2(X_train_second)\n",
    "y_pred_int = []\n",
    "\n",
    "for item in y_pred:\n",
    "    y_pred_int.append(round(float(item[0])))\n",
    "print(y_pred_int)\n",
    "print(y_train_second)\n",
    "print(np.sum(y_pred_int==np.array(y_train_second))/len(y_train_second))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "tensor([1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1.])\n",
      "0.8909090909090909\n"
     ]
    }
   ],
   "source": [
    "### accuracy on training set\n",
    "y_pred = model2(X_train_second)\n",
    "y_pred_int = []\n",
    "\n",
    "for item in y_pred:\n",
    "    y_pred_int.append(round(float(item[0])))\n",
    "print(y_pred_int)\n",
    "print(y_train_second)\n",
    "print(np.sum(y_pred_int==np.array(y_train_second))/len(y_pred_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for Dataset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward_third(torch.nn.Module):\n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Feedforward_third, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.batchnorm = torch.nn.BatchNorm1d(self.hidden_size)\n",
    "            self.laynorm = torch.nn.LayerNorm(self.input_size)\n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size, bias=True)\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, 5, bias=True)\n",
    "            self.fc3 = torch.nn.Linear(5, 1, bias=True)\n",
    "            self.sigmoid = torch.nn.Sigmoid()\n",
    "        def forward(self, x):\n",
    "            hidden = self.fc1(x)\n",
    "            batchnorm = self.batchnorm(hidden)\n",
    "            laynorm = self.laynorm(batchnorm)\n",
    "            relu = self.relu(laynorm)\n",
    "            output = self.fc2(relu)\n",
    "            output = self.fc3(output)\n",
    "            output = self.sigmoid(output)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Feedforward_third(X_train_third.shape[1],13)\n",
    "criterion3 = torch.nn.BCELoss()\n",
    "optimizer3 = torch.optim.Adam(model3.parameters(), lr = 0.01, weight_decay= 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 0.687207818031311\n",
      "Epoch 1: train loss: 0.6589178442955017\n",
      "Epoch 2: train loss: 0.6377346515655518\n",
      "Epoch 3: train loss: 0.6212764978408813\n",
      "Epoch 4: train loss: 0.6082321405410767\n",
      "Epoch 5: train loss: 0.5975087285041809\n",
      "Epoch 6: train loss: 0.588122546672821\n",
      "Epoch 7: train loss: 0.5793818831443787\n",
      "Epoch 8: train loss: 0.5716533064842224\n",
      "Epoch 9: train loss: 0.564481794834137\n",
      "Epoch 10: train loss: 0.5579599738121033\n",
      "Epoch 11: train loss: 0.551609456539154\n",
      "Epoch 12: train loss: 0.544535219669342\n",
      "Epoch 13: train loss: 0.5362147688865662\n",
      "Epoch 14: train loss: 0.5263724327087402\n",
      "Epoch 15: train loss: 0.5149628520011902\n",
      "Epoch 16: train loss: 0.5031763911247253\n",
      "Epoch 17: train loss: 0.4914756715297699\n",
      "Epoch 18: train loss: 0.47966742515563965\n",
      "Epoch 19: train loss: 0.4669191241264343\n",
      "Epoch 20: train loss: 0.4529743492603302\n",
      "Epoch 21: train loss: 0.43830907344818115\n",
      "Epoch 22: train loss: 0.42560625076293945\n",
      "Epoch 23: train loss: 0.413156121969223\n",
      "Epoch 24: train loss: 0.4005880653858185\n",
      "Epoch 25: train loss: 0.38760268688201904\n",
      "Epoch 26: train loss: 0.3764569163322449\n",
      "Epoch 27: train loss: 0.3654005825519562\n",
      "Epoch 28: train loss: 0.35379353165626526\n",
      "Epoch 29: train loss: 0.34346672892570496\n",
      "Epoch 30: train loss: 0.3350326120853424\n",
      "Epoch 31: train loss: 0.326316237449646\n",
      "Epoch 32: train loss: 0.31732988357543945\n",
      "Epoch 33: train loss: 0.3091748356819153\n",
      "Epoch 34: train loss: 0.3013618588447571\n",
      "Epoch 35: train loss: 0.29281890392303467\n",
      "Epoch 36: train loss: 0.2836873233318329\n",
      "Epoch 37: train loss: 0.27780091762542725\n",
      "Epoch 38: train loss: 0.27214115858078003\n",
      "Epoch 39: train loss: 0.2656048834323883\n",
      "Epoch 40: train loss: 0.25832468271255493\n",
      "Epoch 41: train loss: 0.25146690011024475\n",
      "Epoch 42: train loss: 0.2454959899187088\n",
      "Epoch 43: train loss: 0.2387537658214569\n",
      "Epoch 44: train loss: 0.23288951814174652\n",
      "Epoch 45: train loss: 0.22741204500198364\n",
      "Epoch 46: train loss: 0.22222016751766205\n",
      "Epoch 47: train loss: 0.2166440337896347\n",
      "Epoch 48: train loss: 0.21083495020866394\n",
      "Epoch 49: train loss: 0.2067575603723526\n",
      "Epoch 50: train loss: 0.20257866382598877\n",
      "Epoch 51: train loss: 0.19808495044708252\n",
      "Epoch 52: train loss: 0.19395890831947327\n",
      "Epoch 53: train loss: 0.18895162642002106\n",
      "Epoch 54: train loss: 0.18416662514209747\n",
      "Epoch 55: train loss: 0.18018601834774017\n",
      "Epoch 56: train loss: 0.17626336216926575\n",
      "Epoch 57: train loss: 0.1720171719789505\n",
      "Epoch 58: train loss: 0.16788098216056824\n",
      "Epoch 59: train loss: 0.16373944282531738\n",
      "Epoch 60: train loss: 0.15839844942092896\n",
      "Epoch 61: train loss: 0.15328113734722137\n",
      "Epoch 62: train loss: 0.14863604307174683\n",
      "Epoch 63: train loss: 0.14307630062103271\n",
      "Epoch 64: train loss: 0.13818979263305664\n",
      "Epoch 65: train loss: 0.13398157060146332\n",
      "Epoch 66: train loss: 0.12867866456508636\n",
      "Epoch 67: train loss: 0.1247144490480423\n",
      "Epoch 68: train loss: 0.1199524998664856\n",
      "Epoch 69: train loss: 0.11514578759670258\n",
      "Epoch 70: train loss: 0.11114443838596344\n",
      "Epoch 71: train loss: 0.10677287727594376\n",
      "Epoch 72: train loss: 0.10153136402368546\n",
      "Epoch 73: train loss: 0.0957450270652771\n",
      "Epoch 74: train loss: 0.09172350913286209\n",
      "Epoch 75: train loss: 0.0869927629828453\n",
      "Epoch 76: train loss: 0.08302231132984161\n",
      "Epoch 77: train loss: 0.07943857461214066\n",
      "Epoch 78: train loss: 0.07506006211042404\n",
      "Epoch 79: train loss: 0.07252559810876846\n",
      "Epoch 80: train loss: 0.06844457238912582\n",
      "Epoch 81: train loss: 0.06503855437040329\n",
      "Epoch 82: train loss: 0.06268005073070526\n",
      "Epoch 83: train loss: 0.05820804461836815\n",
      "Epoch 84: train loss: 0.055514171719551086\n",
      "Epoch 85: train loss: 0.052724871784448624\n",
      "Epoch 86: train loss: 0.04964694008231163\n",
      "Epoch 87: train loss: 0.04707073047757149\n",
      "Epoch 88: train loss: 0.044376179575920105\n",
      "Epoch 89: train loss: 0.04184054583311081\n",
      "Epoch 90: train loss: 0.03957128897309303\n",
      "Epoch 91: train loss: 0.03740691393613815\n",
      "Epoch 92: train loss: 0.03526104614138603\n",
      "Epoch 93: train loss: 0.03316797688603401\n",
      "Epoch 94: train loss: 0.03208363428711891\n",
      "Epoch 95: train loss: 0.03012138232588768\n",
      "Epoch 96: train loss: 0.02868102304637432\n",
      "Epoch 97: train loss: 0.02669014036655426\n",
      "Epoch 98: train loss: 0.025653598830103874\n",
      "Epoch 99: train loss: 0.023643268272280693\n"
     ]
    }
   ],
   "source": [
    "model3.train()\n",
    "epoch = 100\n",
    "loss_array = []\n",
    "for epoch in range(epoch):\n",
    "    optimizer3.zero_grad()\n",
    "    # Forward pass\n",
    "    y_pred = model3(X_train_third)\n",
    "    # Compute Loss\n",
    "    loss = criterion3(y_pred.squeeze(), y_train_third)\n",
    "    loss_array.append(float(loss.item()))\n",
    "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer3.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss Value')"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_array)\n",
    "plt.title(\"Training Loss of ANN\")\n",
    "plt.xlabel(\"Epoches\")\n",
    "plt.ylabel(\"Loss Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "110\n",
      "0.8636363636363636\n"
     ]
    }
   ],
   "source": [
    "model3.eval()\n",
    "y_pred = model3(X_train_third)\n",
    "y_pred_int = []\n",
    "\n",
    "for item in y_pred:\n",
    "    y_pred_int.append(round(float(item[0])))\n",
    "    \n",
    "print(len(y_pred_int))\n",
    "print(len(y_train_third))\n",
    "y_train_third = np.array(y_train_third)\n",
    "print(np.sum(y_pred_int==y_train_third)/len(y_pred_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "[1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "0.8636363636363636\n"
     ]
    }
   ],
   "source": [
    "### accuracy on training set\n",
    "y_pred = model3(X_train_third)\n",
    "y_pred_int = []\n",
    "\n",
    "for item in y_pred:\n",
    "    y_pred_int.append(round(float(item[0])))\n",
    "print(y_pred_int)\n",
    "print(y_train_third)\n",
    "print(np.sum(y_pred_int==np.array(y_train_third))/len(y_pred_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outside Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file = f'外部验证最新.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>性别</th>\n",
       "      <th>年龄</th>\n",
       "      <th>吸烟</th>\n",
       "      <th>部位</th>\n",
       "      <th>原发灶大小</th>\n",
       "      <th>骨转移</th>\n",
       "      <th>脑转移</th>\n",
       "      <th>肝转</th>\n",
       "      <th>肺内转移</th>\n",
       "      <th>胸膜转移</th>\n",
       "      <th>治疗方案</th>\n",
       "      <th>突变情况123</th>\n",
       "      <th>TP53</th>\n",
       "      <th>rb1</th>\n",
       "      <th>pik3ca</th>\n",
       "      <th>result</th>\n",
       "      <th>ANN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    性别  年龄  吸烟  部位  原发灶大小  骨转移  脑转移  肝转  肺内转移  胸膜转移  治疗方案  突变情况123  TP53  rb1  \\\n",
       "0    1  56   0   1      1    1    1   1     1     0     1        2     1    0   \n",
       "1    2  81   0   2      2    1    1   0     1     1     1        2     0    0   \n",
       "2    2  75   0   1      2    1    0   0     1     1     1        2     0    0   \n",
       "3    2  74   0   2      1    1    0   1     1     0     1        1     0    0   \n",
       "4    1  59   0   1      2    1    0   0     0     1     1        1     0    0   \n",
       "5    2  71   0   2      2    1    0   0     1     1     1        2     1    0   \n",
       "6    2  51   0   2      3    0    0   0     1     0     1        3     0    1   \n",
       "7    1  62   0   1      1    0    0   0     1     1     1        2     0    0   \n",
       "8    2  67   0   1      2    1    0   0     1     1     1        2     1    0   \n",
       "9    1  77   0   2      2    0    0   0     1     1     1        1     1    0   \n",
       "10   2  85   0   2      2    1    0   0     1     1     1        2     1    0   \n",
       "11   2  62   0   2      2    0    1   0     1     1     1        1     0    0   \n",
       "12   1  89   0   1      3    0    0   0     1     1     1        1     0    0   \n",
       "13   1  72   1   2      2    1    0   0     1     0     1        1     0    0   \n",
       "14   2  47   0   2      3    1    1   0     1     1     1        2     0    0   \n",
       "15   1  68   1   2      2    0    0   0     1     1     1        1     1    0   \n",
       "16   1  76   1   1      2    1    0   0     1     0     1        2     1    0   \n",
       "17   1  70   0   1      2    0    0   0     1     1     1        1     1    0   \n",
       "18   1  46   0   2      1    1    0   0     1     0     1        1     1    0   \n",
       "19   2  47   0   2      1    0    0   0     1     0     1        1     0    0   \n",
       "20   2  57   0   2      2    1    1   0     0     0     1        2     0    0   \n",
       "21   2  64   0   1      2    0    0   0     1     1     1        2     1    0   \n",
       "22   2  62   0   1      2    0    0   0     0     1     1        1     0    0   \n",
       "23   1  58   0   1      3    1    0   0     1     1     1        2     0    0   \n",
       "24   1  62   0   2      1    0    1   0     1     1     1        1     1    0   \n",
       "25   2  81   0   1      1    0    0   0     1     0     1        1     0    0   \n",
       "26   1  64   0   2      2    1    1   0     1     1     1        2     0    0   \n",
       "27   2  49   0   1      2    1    0   0     1     0     1        2     1    0   \n",
       "28   2  68   0   1      1    1    0   0     0     0     1        2     0    0   \n",
       "29   1  78   0   2      2    1    0   1     1     0     1        2     0    0   \n",
       "\n",
       "    pik3ca  result  ANN  \n",
       "0        0       0    1  \n",
       "1        0       0    0  \n",
       "2        0       0    1  \n",
       "3        0       1    1  \n",
       "4        0       1    1  \n",
       "5        0       0    1  \n",
       "6        0       0    0  \n",
       "7        0       1    1  \n",
       "8        0       1    0  \n",
       "9        0       1    1  \n",
       "10       0       1    1  \n",
       "11       0       0    0  \n",
       "12       0       1    1  \n",
       "13       0       1    1  \n",
       "14       0       0    0  \n",
       "15       0       1    1  \n",
       "16       0       1    1  \n",
       "17       1       0    0  \n",
       "18       0       1    1  \n",
       "19       0       1    0  \n",
       "20       0       1    0  \n",
       "21       0       1    1  \n",
       "22       0       1    1  \n",
       "23       0       1    0  \n",
       "24       0       0    1  \n",
       "25       0       1    1  \n",
       "26       0       0    0  \n",
       "27       0       1    1  \n",
       "28       0       1    1  \n",
       "29       0       1    1  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataframe2 = pd.read_excel(new_file, sheet_name=0)\n",
    "new_dataframe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., 56.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  2.,  1.,  0.,\n",
       "          0.],\n",
       "        [ 2., 81.,  0.,  2.,  2.,  1.,  1.,  0.,  1.,  1.,  1.,  2.,  0.,  0.,\n",
       "          0.],\n",
       "        [ 2., 75.,  0.,  1.,  2.,  1.,  0.,  0.,  1.,  1.,  1.,  2.,  0.,  0.,\n",
       "          0.],\n",
       "        [ 2., 74.,  0.,  2.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,  1.,  0.,  0.,\n",
       "          0.],\n",
       "        [ 1., 59.,  0.,  1.,  2.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,\n",
       "          0.],\n",
       "        [ 2., 71.,  0.,  2.,  2.,  1.,  0.,  0.,  1.,  1.,  1.,  2.,  1.,  0.,\n",
       "          0.],\n",
       "        [ 2., 51.,  0.,  2.,  3.,  0.,  0.,  0.,  1.,  0.,  1.,  3.,  0.,  1.,\n",
       "          0.],\n",
       "        [ 1., 62.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  2.,  0.,  0.,\n",
       "          0.],\n",
       "        [ 2., 67.,  0.,  1.,  2.,  1.,  0.,  0.,  1.,  1.,  1.,  2.,  1.,  0.,\n",
       "          0.],\n",
       "        [ 1., 77.,  0.,  2.,  2.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
       "          0.],\n",
       "        [ 2., 85.,  0.,  2.,  2.,  1.,  0.,  0.,  1.,  1.,  1.,  2.,  1.,  0.,\n",
       "          0.],\n",
       "        [ 2., 62.,  0.,  2.,  2.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
       "          0.],\n",
       "        [ 1., 89.,  0.,  1.,  3.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
       "          0.],\n",
       "        [ 1., 72.,  1.,  2.,  2.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,\n",
       "          0.],\n",
       "        [ 2., 47.,  0.,  2.,  3.,  1.,  1.,  0.,  1.,  1.,  1.,  2.,  0.,  0.,\n",
       "          0.],\n",
       "        [ 1., 68.,  1.,  2.,  2.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
       "          0.],\n",
       "        [ 1., 76.,  1.,  1.,  2.,  1.,  0.,  0.,  1.,  0.,  1.,  2.,  1.,  0.,\n",
       "          0.],\n",
       "        [ 1., 70.,  0.,  1.,  2.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
       "          1.],\n",
       "        [ 1., 46.,  0.,  2.,  1.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,  1.,  0.,\n",
       "          0.],\n",
       "        [ 2., 47.,  0.,  2.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,\n",
       "          0.],\n",
       "        [ 2., 57.,  0.,  2.,  2.,  1.,  1.,  0.,  0.,  0.,  1.,  2.,  0.,  0.,\n",
       "          0.],\n",
       "        [ 2., 64.,  0.,  1.,  2.,  0.,  0.,  0.,  1.,  1.,  1.,  2.,  1.,  0.,\n",
       "          0.],\n",
       "        [ 2., 62.,  0.,  1.,  2.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,\n",
       "          0.],\n",
       "        [ 1., 58.,  0.,  1.,  3.,  1.,  0.,  0.,  1.,  1.,  1.,  2.,  0.,  0.,\n",
       "          0.],\n",
       "        [ 1., 62.,  0.,  2.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
       "          0.],\n",
       "        [ 2., 81.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,\n",
       "          0.],\n",
       "        [ 1., 64.,  0.,  2.,  2.,  1.,  1.,  0.,  1.,  1.,  1.,  2.,  0.,  0.,\n",
       "          0.],\n",
       "        [ 2., 49.,  0.,  1.,  2.,  1.,  0.,  0.,  1.,  0.,  1.,  2.,  1.,  0.,\n",
       "          0.],\n",
       "        [ 2., 68.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  2.,  0.,  0.,\n",
       "          0.],\n",
       "        [ 1., 78.,  0.,  2.,  2.,  1.,  0.,  1.,  1.,  0.,  1.,  2.,  0.,  0.,\n",
       "          0.]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_frame2 = new_dataframe2.iloc[:,range(15)]\n",
    "x_test_frame2 = torch.Tensor(np.array(x_test_frame2))\n",
    "x_test_frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>性别</th>\n",
       "      <th>年龄</th>\n",
       "      <th>吸烟</th>\n",
       "      <th>部位</th>\n",
       "      <th>原发灶大小</th>\n",
       "      <th>骨转移</th>\n",
       "      <th>脑转移</th>\n",
       "      <th>肝转</th>\n",
       "      <th>肺内转移</th>\n",
       "      <th>胸膜转移</th>\n",
       "      <th>治疗方案</th>\n",
       "      <th>突变情况123</th>\n",
       "      <th>TP53</th>\n",
       "      <th>rb1</th>\n",
       "      <th>pik3ca</th>\n",
       "      <th>result</th>\n",
       "      <th>ANN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    性别  年龄  吸烟  部位  原发灶大小  骨转移  脑转移  肝转  肺内转移  胸膜转移  治疗方案  突变情况123  TP53  rb1  \\\n",
       "0    1  56   0   1      1    1    1   1     1     0     1        2     1    0   \n",
       "1    2  81   0   2      2    1    1   0     1     1     1        2     0    0   \n",
       "2    2  75   0   1      2    1    0   0     1     1     1        2     0    0   \n",
       "3    2  74   0   2      1    1    0   1     1     0     1        1     0    0   \n",
       "4    1  59   0   1      2    1    0   0     0     1     1        1     0    0   \n",
       "5    2  71   0   2      2    1    0   0     1     1     1        2     1    0   \n",
       "6    2  51   0   2      3    0    0   0     1     0     1        3     0    1   \n",
       "7    1  62   0   1      1    0    0   0     1     1     1        2     0    0   \n",
       "8    2  67   0   1      2    1    0   0     1     1     1        2     1    0   \n",
       "9    1  77   0   2      2    0    0   0     1     1     1        1     1    0   \n",
       "10   2  85   0   2      2    1    0   0     1     1     1        2     1    0   \n",
       "11   2  62   0   2      2    0    1   0     1     1     1        1     0    0   \n",
       "12   1  89   0   1      3    0    0   0     1     1     1        1     0    0   \n",
       "13   1  72   1   2      2    1    0   0     1     0     1        1     0    0   \n",
       "14   2  47   0   2      3    1    1   0     1     1     1        2     0    0   \n",
       "15   1  68   1   2      2    0    0   0     1     1     1        1     1    0   \n",
       "16   1  76   1   1      2    1    0   0     1     0     1        2     1    0   \n",
       "17   1  70   0   1      2    0    0   0     1     1     1        1     1    0   \n",
       "18   1  46   0   2      1    1    0   0     1     0     1        1     1    0   \n",
       "19   2  47   0   2      1    0    0   0     1     0     1        1     0    0   \n",
       "20   2  57   0   2      2    1    1   0     0     0     1        2     0    0   \n",
       "21   2  64   0   1      2    0    0   0     1     1     1        2     1    0   \n",
       "22   2  62   0   1      2    0    0   0     0     1     1        1     0    0   \n",
       "23   1  58   0   1      3    1    0   0     1     1     1        2     0    0   \n",
       "24   1  62   0   2      1    0    1   0     1     1     1        1     1    0   \n",
       "25   2  81   0   1      1    0    0   0     1     0     1        1     0    0   \n",
       "26   1  64   0   2      2    1    1   0     1     1     1        2     0    0   \n",
       "27   2  49   0   1      2    1    0   0     1     0     1        2     1    0   \n",
       "28   2  68   0   1      1    1    0   0     0     0     1        2     0    0   \n",
       "29   1  78   0   2      2    1    0   1     1     0     1        2     0    0   \n",
       "\n",
       "    pik3ca  result  ANN  \n",
       "0        0       0    1  \n",
       "1        0       0    0  \n",
       "2        0       0    1  \n",
       "3        0       1    1  \n",
       "4        0       1    1  \n",
       "5        0       0    1  \n",
       "6        0       0    0  \n",
       "7        0       1    1  \n",
       "8        0       1    0  \n",
       "9        0       1    1  \n",
       "10       0       1    1  \n",
       "11       0       0    0  \n",
       "12       0       1    1  \n",
       "13       0       1    1  \n",
       "14       0       0    0  \n",
       "15       0       1    1  \n",
       "16       0       1    1  \n",
       "17       1       0    0  \n",
       "18       0       1    1  \n",
       "19       0       1    0  \n",
       "20       0       1    0  \n",
       "21       0       1    1  \n",
       "22       0       1    1  \n",
       "23       0       1    0  \n",
       "24       0       0    1  \n",
       "25       0       1    1  \n",
       "26       0       0    0  \n",
       "27       0       1    1  \n",
       "28       0       1    1  \n",
       "29       0       1    1  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataframe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_frame2 = new_dataframe2.iloc[:,-2]\n",
    "y_test_frame2 = np.array(y_test_frame2)\n",
    "y_test_frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1]\n",
      "[0 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1]\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "y_pred_outside = model2(x_test_frame2)\n",
    "y_pred_outside_int = []\n",
    "\n",
    "for item in y_pred_outside:\n",
    "    y_pred_outside_int.append(round(float(item[0])))\n",
    "\n",
    "y_pred_outside_int = np.array(y_pred_outside_int)\n",
    "print(y_pred_outside_int)\n",
    "print(y_test_frame2)\n",
    "print(np.sum(y_test_frame2==y_pred_outside_int)/len(y_pred_outside))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
